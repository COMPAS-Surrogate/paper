% Define document class
\documentclass[twocolumn]{aastex631}
\usepackage{showyourwork}


\usepackage{natbib}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsmath,units}
\usepackage{amsmath,bm}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{acronym}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{calc}
\usepackage[caption=false]{subfig}
\usepackage{import}
\usepackage{mathtools}
\usepackage{showyourwork}


\usepackage{float}
\makeatletter
\let\newfloat\newfloat@ltx
\makeatother

\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}

\setlength{\marginparwidth}{1.5cm}



% table column types
\usepackage{array}
\newcolumntype{E}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{F}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{G}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}


% abbreviations/acronyms
\acrodef{ANN}{artificial neural network}
\acrodef{DCO}{double compact object}
\acrodef{MCMC}{Markov Chain Monte Carlo}
\acrodef{MSSFR}{metallicity-specific star formation rate}
\acrodef{LVK}{LIGO--VIRGO--KAGRA}



\newcommand\COMPAS{{\sc{COMPAS}}\xspace}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\newcommand{\MSFR}{\ensuremath{{M}_{\rm{SFR}}}\xspace}
\newcommand{\ts}{\ensuremath{{t}_{\rm{s}}}\xspace}
\newcommand{\tsup}{\textsuperscript}
\newcommand{\Vc}{\ensuremath{{V}_{\rm{c}}}\xspace}

\newcommand{\monei}{\ensuremath{m_{1,\rm{i}}}\xspace}
\newcommand{\mtwoi}{\ensuremath{m_{2,\rm{i}}}\xspace}
\newcommand{\monef}{\ensuremath{m_{1,\rm{f}}}\xspace}
\newcommand{\mtwof}{\ensuremath{m_{2,\rm{f}}}\xspace}
\newcommand{\ai}{\ensuremath{a_{\rm{i}}}\xspace}
\newcommand{\qi}{\ensuremath{q_{\rm{i}}}\xspace}
\newcommand{\Zi}{\ensuremath{Z_{\rm{i}}}\xspace}
\newcommand{\vk}{\ensuremath{v_{\rm{k}}}\xspace}
\newcommand{\thetak}{\ensuremath{{\theta}_{\rm{k}}}\xspace}
\newcommand{\phik}{\ensuremath{{\phi}_{\rm{k}}}\xspace}
\newcommand{\ei}{\ensuremath{{e}_{\rm{i}}}\xspace}

\newcommand{\Msun}{\ensuremath{\,\rm{M}_{\odot}}\xspace}
\newcommand{\Zsun}{\ensuremath{\,\rm{Z}_{\odot}}\xspace}
\newcommand{\kms}{\ensuremath{\,\rm{km}\,\rm{s}^{-1}}\xspace}
\newcommand{\AU}{\ensuremath{\,\mathrm{AU}}\xspace}
\newcommand{\Mc}{\ensuremath{\mathcal{M}}\xspace}

\newcommand{\Lmain}{\ensuremath{\mathcal{L}(\mathcal{D}|\lambda)}\xspace}
\newcommand{\Lp}{\ensuremath{\mathcal{L}_{\rm p}}\xspace}
\newcommand{\Le}{\ensuremath{\mathcal{L}_{\rm event}}\xspace}
\newcommand{\pg}{\ensuremath{p_{\rm grid}}\xspace}
\newcommand{\Lsurr}{\ensuremath{\mathcal{L}^{\star}(\lambda)}\xspace}


%%%%%%%%%%%%%%% SYMBOLS

% Projects:
\newcommand{\project}[1]{\textsf{#1}}

\newcommand{\python}{\project{Python}}
\newcommand{\jupyter}{\project{Jupyter}}

\newcommand{\exoplanet}{\project{exoplanet}}
\newcommand{\lightkurve}{\project{lightkurve}}
\newcommand{\starry}{\project{starry}}
\newcommand{\pymc}{\project{PyMC3}}
\newcommand{\pymcextra}{\project{pymc3-ext}}
\newcommand{\celerite}{\project{celerite}}
\newcommand{\astropy}{\project{astropy}}
\newcommand{\scipy}{\project{scipy}}
\newcommand{\jupytext}{\project{jupytext}}
\newcommand{\sphinx}{\project{sphinx}}
\newcommand{\jupyterbook}{\project{Jupyter-book}}
\newcommand{\arviz}{\project{ArviZ}}
\newcommand{\nbconvert}{\project{nbconvert}}
\newcommand{\numpy}{\project{numpy}}
\newcommand{\pandas}{\project{pandas}}
\newcommand{\matplotlib}{\project{matplotlib}}
\newcommand{\corner}{\project{corner}}
\newcommand{\emcee}{\project{emcee}}
\newcommand{\trieste}{\project{trieste}}
\newcommand{\tensorflow}{\project{TensorFlow}}
\newcommand{\pycbc}{\project{PyCBC}}



\newcommand{\LVK}{\project{LVK}}
\newcommand{\mast}{\project{MAST}}
\newcommand{\exofop}{\project{ExoFOP}}
\newcommand{\tessAtlas}{\project{TESS Atlas}}
\newcommand{\ogc}{\project{4-OGC}}

% math
\newcommand{\T}{\ensuremath{\mathrm{T}}}
\newcommand{\dd}{\ensuremath{ \mathrm{d}}}
% \newcommand{\unit}[1]{{\ensuremath{ \mathrm{#1}}}}
\newcommand{\bvec}[1]{{\ensuremath{\boldsymbol{#1}}}}


\DeclareMathOperator{\invG}{Inv-\mathnormal{\Gamma}}
\DeclareMathOperator{\N}{\mathcal{N}}
\DeclareMathOperator{\U}{\mathcal{U}}
\DeclareMathOperator{\Un}{\mathcal{U}}
\DeclareMathOperator{\Par}{\mathcal{P}ar}
\DeclareMathOperator{\tmin}{\mathnormal{t_{\rm min}}}
\DeclareMathOperator{\tmax}{\mathnormal{t_{\rm max}}}





%% affiliation shortcuts
\newcommand{\SPA}{School of Physics and Astronomy, Monash University, Clayton VIC 3800, Australia}
\newcommand{\OzGravMonash}{OzGrav: The ARC Centre of Excellence for Gravitational Wave Discovery, Clayton VIC 3800, Australia}
\newcommand{\AMNH}{Department of Astrophysics, American Museum of Natural History, New York, NY 10024, USA}
\newcommand{\CCA}{Center for Computational Astrophysics, Flatiron Institute, New York, NY 10010, USA}
\newcommand{\CUNY}{Graduate Center, City University of New York, 365 5th Avenue, New York, NY 10016, USA}
\newcommand{\BMCC}{Department of Science, BMCC, City University of New York, New York, NY 10007, USA}







%%%%%%%%%%%%%%%%%%%%%%%%




%%%% 

\definecolor{orange-red}{rgb}{1.0, 0.27, 0.0}
\newcommand{\jeff}[1]{\textbf{\textcolor{orange-red}{#1}}}
\newcommand{\ilya}[1]{\textbf{\textcolor{magenta}{#1}}}
\newcommand{\avi}[1]{\textbf{\textcolor{cyan}{#1}}}
\newcommand{\chayan}[1]{\textbf{\textcolor{green}{#1}}}
\newcommand{\resp}[1]{#1}




% Begin!
\begin{document}

\title{\resp{COMPAS Star-formation LnL GP surrogate}}

% Authors
\author{Avi Vajpeyi}
\affiliation{UoA}
\affiliation{NZ Gravity}
\affiliation{ARC Centre of Excellence for Gravitational Wave Discovery -- OzGrav, Australia}

\author{Jeff Riley}
\affiliation{School of Physics and Astronomy, Monash University, Clayton, Victoria 3800, Australia}
\affiliation{ARC Centre of Excellence for Gravitational Wave Discovery -- OzGrav, Australia}
\author{Ilya Mandel}
\affiliation{School of Physics and Astronomy, Monash University, Clayton, Victoria 3800, Australia}
\affiliation{ARC Centre of Excellence for Gravitational Wave Discovery -- OzGrav, Australia}
\author{Chayan Chatterjee}
\affiliation{}

\correspondingauthor{Avi Vajpeyi}
\email{avi.vajpeyi@auckland.ac.nz}

%%%%


\begin{abstract}
    We're using GPs to build surrogate likelihoods for COMPAS star formation parameters, given the LVK observed dataset.
\end{abstract}

\keywords{surrogate model -- inference -- binaries -- stars: evolution -- gravitational waves -- machine learning -- Gaussian Processes}



\section{Introduction}
\label{sec:intro}
Over the past decade, improvements in detector sensitivity have led to an exponential increase in the rate of GW detections.
With next-generation detectors on the horizon (such as CE, ET, and LISA), the number of GW detections will increase even more.
The most recent catalogue of GW contains
XX events, the majority of them being Binary Black Holes
(BBHs), with XX public alerts for GW that have yet to be confirmed as astrophysiocal events.
As more GW events are observed, more features
in the distribution of GW events await to be discovered.
One of the most common ways to understand the observed GW population is through phenomenological modelling.
However, as the size of the catalogues increases, so does the catalogue complexity, making it challenging to develop interpretable, parameterisable phenomenological models, flexible enough to explain the features in the catalogue.

Alternatively, we can consider using forward models to simulate catalogues of GW events and compare the simulations to observed catalogues.
The forward modelling approach would provide astronomers with constraints on easy-to-interpret physical parameters that describe the initial conditions of the population of merging binaries, such as distributions describing the initial stellar mass, metallicity, and binary separation.
These parameters also govern simulated physical processes like wind mass loss, supernova characteristics, and binary interactions such as mass transfer and common envelope efficiency.
However, the generation of synthetic catalogues from the various rapid population sysnthesis software packages can be expensive, making brute force methods that explore all possible parameter values expensive (for example, see  Broekgaarden et al. (2022)).
Another alternative, as proposed by Riley et al. (2023) involves building surrogate tools to bridge the computational complexities of simulating a state space large enough
to allow us to infer astrophysical constraints from the observed catalogs.

Riley et al. (2023) generated a small number of ``training" states using a
targeted selection of initial conditions and evolutionary
parameters.
The training states were then used to teach an interpolant how to
map initial conditions and evolutionary parameters to
the final state, thus avoiding the computational time
of calculating the intermediate steps.

In their work, they explored four parameters governing the cosmic metallicity-specific star formation rate (MSSFR) in the model of Neijssel et al. (2019).

We build upon Riley at al. (2023)'s work, and

The remainder of this paper is organised as follows.
Section 2 presents a description of the tool we construct
for this proof-of-concept study, and the method used
to train the tool.
We present and discuss our results in Section 3.
We provide some concluding remarks in  Section 4



%--------------------------------------------------------
\section{Method}


\subsection{MSSFR parameters}\label{sec:method_parameters}

The parameters we chose to vary for this study are four free parameters for the calculation of the \ac{MSSFR} in the phenomenological model of \citet{Neijssel_2019}. In this model, the \ac{MSSFR} is split into two parts, the star formation rate (SFR) and the metallicity distribution:


\begin{equation}
  \frac{\diff^3 \MSFR}{\diff \ts \diff \Vc \diff Z}(z) =
  \frac{\diff^2 \MSFR}{\diff \ts \diff \Vc }(z)
  \times
  \frac{\diff P }{\diff Z}(z),
\end{equation}

\noindent
where the SFR is given by:

\begin{equation}
  \frac{\diff^2 \MSFR}{\diff \ts \diff \Vc} =
  a\frac{(1 + z)^b}{1 + (\frac{(1 + z)}{c})^d}\,
  \mathrm{M}_\odot\ \mathrm{yr}^{-1}\ \mathrm{Mpc}^{-3},
\end{equation}

\bigskip\noindent
and we use a log-normal distribution in metallicity at each redshift (cf.~the skewed log-normal model proposed by \citet{vanSon_2022}):

\begin{equation}
  \frac{\diff P }{\diff Z}(z) =
  \frac{1}{Z\sigma\sqrt{2\pi}}\, \exp\bigg[{-\frac{(\ln Z-\ln \langle Z \rangle +\sigma^2/2)^2}{2\sigma^2}}\bigg],
\end{equation}

\bigskip\noindent
with a redshift-independent standard deviation $\sigma$ in $\ln Z$ space around a redshift-dependent mean $\mu$ of $\ln Z$ given by:

\begin{equation}
  \langle Z \rangle =
  \exp[\mu + \sigma^2/2],
\end{equation}

\bigskip\noindent
with mean metallicity parametrised as in \citet{Langer_2006}:

\begin{equation}
  \langle Z(z) \rangle =
  Z_{0}10^{\alpha{z}}
\end{equation}

\bigskip\noindent
We vary SFR parameters $a$ and $d$, and the metallicity distribution parameters $\alpha$ and $\sigma$, in this study, while fixing $b=2.77$, $c=2.9$, and $Z_0=0.035$.  \resp{\citet{Neijssel_2019} demonstrated that a range of star-formation history models can be mimicked by varying only this subset of \ac{MSSFR} parameters.  We therefore choose to vary the same parameters for consistency with their analysis.  Moreover, reducing the number of parameters allows us to limit computational complexity for this proof-of-principle study.}


\subsection{Cosmic integration}
Talk about how we run cosmic int,
show plots of Mcz grid for different SF

\subsection{Bayesian Model}
Given $N_{\mathrm{obs}}$ observations from data  $\mathcal{D} \equiv \{D_1, D_2, ... D_{N_{\mathrm{obs}}}\}$, we define the likelihood $\mathcal{L}$ that we will see data $\mathcal{D}$ for a particular set of parameters $\lambda$ as
\begin{equation}
  \log{\Lmain} = \log{\Lp\left(N_{\mathrm{obs}}|\lambda\right)} +
  \sum_{i=1}^{N_\mathrm{obs}} \log{\Le(D_i|\lambda)}\ .
  \label{eq:methods_likelihood}
\end{equation}

\bigskip
The first term of Equation~\ref{eq:methods_likelihood} is a Poisson likelihood on there being $N_\mathrm{obs}$ detections,

\begin{equation}
  %\notag
  \log{ \Lp\left(N_{\mathrm{obs}}|\lambda\right)} = - \mu(\lambda) + N_{\mathrm{obs}}\log\mu(\lambda) ,
  \label{eq:methods_likelihood_term1}
\end{equation}

\bigskip\noindent
where $\mu(\lambda)$ is the expected number of observations and we omit terms that depend on the data only and therefore disappear on normalisation, such as $\log(N_{\mathrm{obs}}!)$ and permutation coefficients.

The second term of Equation~\ref{eq:methods_likelihood} is comprised of a product of the probabilities of individual event detections,

\begin{equation}
  %\notag
  \Le(D_i|\lambda) = \pg(z=z_i,\mathcal{M}=\mathcal{M}_{i}|\lambda),
  \label{eq:methods_likelihood_term2}
\end{equation}

\bigskip\noindent
where $\pg(z=z_i,\mathcal{M}=\mathcal{M}_{i}|\lambda)$ is the entry in the probability distribution matrix $\pg(z,\mathcal{M}|\lambda)$ in the $z$ and $\mathcal{M}$ bin of the observed $i^{th}$ event.

The probability distribution matrix $\pg(z,\mathcal{M}|\lambda)$ is constructed by dividing the entries in the matrix of expected detections for a given $\lambda$, generated by multiplying the surrogate model detection rate matrix by the run duration, by the sum of the entries in the matrix, $\mu$.


 In practice, we may not know the values $z_i, \Mc_{i}$ perfectly,  but may only have $K$ samples from a posterior $p(z_i,\Mc_{i}|D_i)$.
 Hence the probability $\Le(z=z_i,\Mc=\Mc_{i}|\lambda)$ for the  $i^{th}$ event in Equation~\ref{eq:methods_likelihood_term2} can be re-written as 

\begin{equation}
  \Le(D_i|\lambda) = \frac{1}{K} \sum_{k=1}^K \frac{\pg(z=z_i^k, \Mc=\Mc_{i}^k|\lambda)}{\pi(z_i^k,\Mc_i^k)},
  \label{eq:methods_likelihood_term2_LIGO}
\end{equation}

\bigskip\noindent
where the subscript $k$ refers to the $k^{th}$ posterior sample among $K$ available samples, and $\pi(z,\Mc)$ is the prior used in the original inference for the event~\citep[see, e.g.][]{Mandel_2019}.

 If the number of bins where an event has posterior support is much smaller than the number of samples $K$, it may be more efficient to pre-compute the weight that each observed event $i$ contributes to each of the bins $b$, $w_{i,b}$, which is independent of $\lambda$:

\begin{equation}
    w_{i,b} = \frac{1}{K} \sum^K_{k=1} \frac{I(\{z^k_i,\Mc^k_i\} \in b)}{\pi(z_i^k,\Mc_i^k)} \ ,
\end{equation}
where $I(\{z^k_i,\Mc^k_i\} \in b$ is an indicator function that evaluates to 1 if sample $\{z^k_i,\Mc^k_i\}$ falls into bin $b$ and $0$ otherwise.
Then the probability $\Le(D_i|\lambda)$ can be evaluated as a sum over bins,

\begin{equation}
    \Le(D_i|\lambda) = \sum_b \pg(z^b, \Mc^b | \lambda)\,  w_{i,b}\, .
\end{equation}


Unfortunatly, \Lmain is an expensive function, making it hard to sample with. 
In the next section, we discuss a surrogate model for \Lmain that is cheaper to sample with.

\subsection{GP surrogate using Bayesian optimisation }
Given  $M$ ``observations" of \Lmain, $\{\mathcal{L}(\lambda_0), ..., \mathcal{L}(\lambda_M)\}$, we  define a conditional probabilty distribution
\begin{align}
    \Lsurr &= \mathcal{GP}( \mathcal{L}(\lambda) | \mathcal{L}(\lambda_0), ..., \mathcal{L}(\lambda_M))\, \nonumber \\
    &= \mathcal{GP}(\mu(\lambda), \Sigma(\lambda))
\end{align}
where the conditional probability distribution is given by a Guassian process $\mathcal{GP}$, of mean $\mu$ and covariane $\Sigma$. 
A Gaussian process, provides a Bayesian posterior probability
distribution that describes potential values for $\Lmain$ at a candidate point $\lambda$. 
Each time we observe a new $\mathcal{L}(\lambda')$, this posterior distribution is updated.

\begin{algorithm}
\caption{Basic pseudo-code for Bayesian optimization}
\label{alg:BayesOpt}
\begin{algorithmic}[1] % [1] turns on line numbering
    \STATE Place Gaussian process $\mathcal{GP}$ prior on $\Lmain$
    \STATE Observe $\Lmain$ at $N_0$ points randomly sampled.
    \WHILE{$n \le N$}
        \STATE Update the posterior probability distribution on $\Lmain$ using all available data
        \STATE Let $\lambda_{\rm best}$ be a maximizer of the acquisition function over $\lambda$, where the acquisition function is computed using the current posterior distribution.
        \STATE Observe $L_{\rm best} = \mathcal{L}(\mathcal{D}|\lambda_{\rm best})$.
        \STATE Increment $n$
    \ENDWHILE
    \STATE Return a solution: $\Lsurr \sim \mathcal{GP}(\lambda)$
\end{algorithmic}
\end{algorithm}


The acquisition function measures the value that would be generated by
evaluation of the objective function at a new point $\lambda'$, based on the current posterior distribution over \Lmain. We discuss expected improvement, the most commonly used ac

Bayesian optimisation modeling using Gaussian processes is discussed in detail in~\cite{}.

\tikzstyle{startstop} = [rectangle, rounded corners, 
minimum width=3cm, 
minimum height=1cm,
text centered, 
draw=black, 
fill=red!30]


\tikzstyle{process} = [rectangle, 
minimum width=3cm, 
minimum height=1cm, 
text centered, 
text width=3cm, 
draw=black, 
fill=orange!30]

\tikzstyle{decision} = [diamond, 
minimum width=3cm, 
minimum height=1cm, 
text centered, 
draw=black, 
fill=green!30]
\tikzstyle{arrow} = [thick,->,>=stealth]

\begin{tikzpicture}[node distance=2cm]

\node (start) [startstop] {Sample $\pi(\lambda)$};
\node (compute) [process, below of=start] {Compute $\Lmain$};
\node (train) [process, below of=compute] {Train \Lsurr};
\node (sample) [process, below of=train] {Sample 
$p(\lambda|\mathcal{D})\sim\Lsurr\pi(\lambda)$};
\node (check) [decision, below of=sample, yshift=-0.5cm] {\mathcal{O}(\lambda) > N?};

\node (stop) [startstop, below of=check] {Stop};
\node (acquire) [process, right of=check, xshift=2cm] {Acquire $\lambda$};


\draw [arrow] (start) -- (compute);
\draw [arrow] (compute) -- (train);
\draw [arrow] (train) -- (sample);
\draw [arrow] (sample) -- (check);
\draw [arrow] (check) -- node[anchor=east] {no} (acquire);
\draw [arrow] (check) -- node[anchor=south] {yes} (stop);
\draw [arrow] (acquire) |- (compute);

\end{tikzpicture}

\subsection{Acquisition Functions}

An acquisition function is a function that maps the posterior predictive mean and variance to a scalar value. The scalar value is used to select the next point to observe from the model.

In general, we will write the acquisition function as $\alpha(\mu,\sigma)$, where $\mu$ is the posterior predictive mean and $\sigma$ is the posterior predictive variance.

Each criterion performs a trade-off between exploration i.e. investigating regions where the variance is large and exploitation i.e. investigating regions where the prediction is minimized. 

\paragraph{Uncertainty-based exploration (UE)}

This acquisition function aims at reducing the uncertainty of the GP model. It is defined as

$$
\alpha_{\rm{UE}}^i(\sigma^i)= \sigma^i
$$

and helps to explore the function space in regions of high uncertainty.

One of the most popular BO algorithms is the Efficient Global Optimization (EGO) \cite{jones1998efficient}. 
It uses GP as surrogate model and the Expected Improvement as the infill sampling criterion. This work is focused on BO algorithms using GP and its variants as surrogate models.


\paragraph{Expected Improvement}

This also focuses on the maximisation/minimisation of the GP's posterior predictive mean.
It looks for the best value of $\mu$ so far and then looks for the next point that has a higher probability of being better than the best value so far.

$$
\alpha_{\rm{EI}}^i(\mu^i, \sigma^i)= \sigma^i\ (u^i \mathcal{N}_{\rm CDF}(u^i) \mathcal{N}_{\rm PDF}(u^i)\ ,
$$

where $u^i = \frac{\mu^i - \mu_{\rm{best}}}{\sigma^i}$ and $\mu_{\rm{best}}$ is the best value of $\mu$ so far.

where $\mathcal{N}_{\rm PDF}$ denotes the Probability Density function (PDF) of the univariate Gaussian probability distribution.

While we would like to choose $x$ so that this improvement is large, $f(x)$ is unknown until after the evaluation.  What we can do, however, 
is to take the expected value of this improvement and choose $x$ to maximize it.

The Expected Improvement (EI)takes into account the improvement induced by a candidate that is defined as: $I(\textbf{x})=\text{max}\{0,y_{\text{min}}-f(\textbf{x})\}$. 












\subsection{Diagnostics}

\begin{equation}
    \mathcal{L}^{\star}(\lambda) = \mu_{\mathcal{GP}}(\lambda)
\end{equation}
\begin{equation}
    \mathcal{L}^{\star}_{V}(\lambda) = \mathcal{N}(\mu_{\mathcal{GP}}(\lambda), \sigma_{\mathcal{GP}}(\lambda))
\end{equation}



%--------------------------------------------------------
\section{Inference with surrogate model}

\subsection{Simulation study}

To validate our method, following Section 2.5 of \citep{}, we sample 100 $\lambda$ from a $\pi(\lambda)$, and generate $\vec{\mathcal{D}}$, unique mock \COMPAS populations for each $\lambda$.
We build surrogate likelihoods for each dataset, and use them to approximate $p(\lambda|\mathcal{D})$.
Figure~\ref{fig:simulation_posterior} displays the $p(\lambda|\mathcal{D})$ for one mock population.
The gray ``reference'' posterior is obtained using a surrogate likelihood $\mathcal{L}^{\star}$ tranined with 950 points.
The blue posterior is obtained using a surrogate likelihood $\mathcal{L}^{\star}_V$ trained with 50 points, while the purple posterior's surrogate is built with 325 points. 
The blue posterior has a $D_{KL}>10$ when compared with the gray reference posterior. 
The purple  posterior has a $D_{KL}<1$ when compared with the gray reference posterior, indicating that the two posteriors are similar. 
The orange line marks the true $\lambda$ used to generate the dataset. 
\begin{figure}[ht!]
    \script{plot_simulation_posterior.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/simulation_posterior.pdf}
        \caption{
            Simulation posteriors
        }
        \label{fig:simulation_posterior}
    \end{centering}
\end{figure}


The PP-plot in Figure~\ref{fig:pp_plot} shows that the true value lies withing the correct region of the credible intervals, indicating that the results are not biased.
\begin{figure}[ht!]
    \script{plot_pp_plot.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/pp_plot.pdf}
        \caption{
            PP-plots from simulation study.
        }
        \label{fig:pp_plot}
    \end{centering}
\end{figure}


Finally, Figure~\ref{} shows the JS diveregence 



The catalogue of LIGO, Virgo, and KAGRA (LVK) gravitational wave observations (\citet{GWTC-2_1_zenodo}, \citet{GWTC-3_zenodo}) provides us with a number of merger detections from a population of \acp{DCO}.  For each LVK event we know, among other things, the chirp mass of the merging binary and the merger redshift, up to a measurement uncertainty. We only include confident detections with a minimum astrophysical probability $p_{astro} \ge 0.95$; although less confident events could be included \citep[e.g.][]{Farr_2015}, they will typically contribute little information due to greater measurement uncertainties, so we omit them for this proof-of-concept study.

Once we validate our method, we can use our surrogate model and the LVK data to infer real physical constraints on the parameters under study, with the important caveat that we have fixed the astrophysical parameters, and any errors in those could bias the inferred \ac{MSSFR} model values.

Include corners of variable LnL + normal LnL
Include KL divergence (low number points --> high points)
Include PP plot





\begin{figure}[ht!]
    \script{plot_kl_distances.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/kl_distances.pdf}
        \caption{
            KL-Distances of the posteriors obtained with XX, compared against to those from YY.
        }
        \label{fig:kl_distances}
    \end{centering}
\end{figure}




%--------------------------------------------------------
\section{LVK analysis}
\subsection{Data}

\begin{figure}[ht!]
    \script{plot_ogc4_events.py}
    \begin{centering}
        \includegraphics[width=0.8\columnwidth]{figures/ogc4_events.pdf}
        \caption{
            The events and uncertainty as predicted by Ogc4
        }
        \label{fig:ogc4_events}
    \end{centering}
\end{figure}

\begin{figure}[ht!]
    \script{plot_ogc4_weights.py}
    \begin{centering}
        \includegraphics[width=\linewidth]{figures/ogc4_weights.pdf}
        \caption{
            Weights generated using the OGC4 posteriors
        }
        \label{fig:ogc4_weights}
    \end{centering}
\end{figure}

Describe OGC4 data

\subsection{Results}
Describe LVK results, compare with Riley et al.


%--------------------------------------------------------
\section{Discussion}

We do not 
\begin{itemize}
    \item Do hyper-parameter optimisation for the GP (kernal choices, kernel settings) 
    \item Do hyper-parameter optimisation for the acquisition function 
    \item Explore range of acquisition functions
\end{itemize}


%%% DATA AVAILABILITY %%%
\section*{Data availability}
The data underlying this article is available in the Zenodo deposit for this work. LINK TO ZENODO.

\section*{Acknowledgements}
We gratefully acknowledge the Swinburne Supercomputing OzSTAR Facility for computational resources. All analyses (including test and failed analyses) performed for this study used $XX$K core hours on OzSTAR. This would have amounted to a carbon footprint of ${\sim XX{\text{t CO}_2}}$~\citep{greenhouse, energy_to_co2_converter}. Thankfully, as OzSTAR is powered by wind energy from Iberdrola Australia; the electricity for computations produces negligible carbon waste.
A.V. is supported by the Australian Research Council (ARC) Centre of Excellence CE170100004.

4-OGC.
IM is a recipient of the Australian Research Council Future Fellowship FT190100574.
AV is XX.
Discussions with Renate, Matt, Kate.



\vspace{5mm}
\facilities{LIGO-VIRGO-KAGRA}
%
\software{
\python~\citep{pythonForScientificComputing,pythonForScientists},
\astropy~\citep{astropy},
\COMPAS~\citep{COMPAS_SOFTWARE_2022},
\pycbc~\citep{},
\emcee~\citep{},
\trieste~\citep{},
\tensorflow~\citep{},
\numpy~\citep{numpy},
\scipy~\citep{SciPy},
\pandas~\citep{pandas},
\matplotlib~\citep{matplotlib},
\corner~\citep{corner},
\sphinx~\citep{sphinx_doc},
\jupyterbook~\citep{jupyter,jupyter_book}.
}







\bibliography{bib}

\appendix

\section{$\pi(\mathcal{M}, D_{C})$ to $\pi(\mathcal{M}, z)$}

See \cite{Hogg:1999:arXiv} for transforms

\begin{equation}
\Omega_{\rm M}\equiv\frac{8\pi\,G\,\rho_0}{3\,H_0^2}
\end{equation}
\begin{equation}
\Omega_{\Lambda}\equiv\frac{\Lambda\,c^2}{3\,H_0^2}
\end{equation}
\begin{equation}
    D_H = c / H_0
\end{equation}


\begin{equation}
\label{eq:ez}
E(z)\equiv\sqrt{\Omega_{\rm M}\,(1+z)^3+\Omega_k\,(1+z)^2+\Omega_{\Lambda}}
\end{equation}

\begin{equation}
D_{\rm C} = D_{\rm H}\,\int_0^z\frac{dz'}{E(z')}
\end{equation}

The comoving distance between two events at the same redshift or
distance but separated on the sky by some angle $\delta\theta$ is
$D_{\rm M}\,\delta\theta$ and the transverse comoving distance $D_{\rm
M}$ (so-denoted for a reason explained below) is simply related to the
line-of-sight comoving distance $D_{\rm C}$:
\begin{equation}
D_{\rm M} = \left\{
\begin{array}{ll}
D_{\rm H}\,\frac{1}{\sqrt{\Omega_k}}\,\sinh\left[\sqrt{\Omega_k}\,D_{\rm C}/D_{\rm H}\right] & {\rm for}~\Omega_k>0 \\
D_{\rm C} & {\rm for}~\Omega_k=0 \\
D_{\rm H}\,\frac{1}{\sqrt{|\Omega_k|}}\,\sin\left[\sqrt{|\Omega_k|}\,D_{\rm C}/D_{\rm H}\right] & {\rm for}~\Omega_k<0
\end{array}
\right.
\end{equation}

Angular diameter distance is related to the
transverse comoving distance by
\begin{equation}
D_{\rm A} = \frac{D_{\rm M}}{1+z}
\end{equation}


The comoving volume element in solid
angle $d\Omega$ and redshift interval $dz$ is
\begin{equation}
dV_{\rm C}= D_{\rm H}\,\frac{(1+z)^2\,D_{\rm A}^2}{E(z)}\,d\Omega\,dz
\end{equation}

 The integral of the comoving volume element
from the present to redshift $z$ gives the total comoving volume,
all-sky, out to redshift $z$

\begin{equation}
V_{\rm C} = \left\{
\begin{array}{ll}
  \left(\frac{4\pi\,D_{\rm H}^3}{2\,\Omega_k}\right)\,
  \left[\frac{D_{\rm M}}{D_{\rm H}}\,
  \sqrt{1+\Omega_k\,\frac{D_{\rm M}^2}{D_{\rm H}^2}}
  -\frac{1}{\sqrt{|\Omega_k|}}\,
  {\rm arcsinh}\left(\sqrt{|\Omega_k|}\,\frac{D_{\rm M}}{D_{\rm H}}\right)\right]
  & {\rm for}~\Omega_k>0 \\
  \frac{4\pi}{3}\,D_{\rm M}^3
  & {\rm for}~\Omega_k=0 \\
  \left(\frac{4\pi\,D_{\rm H}^3}{2\,\Omega_k}\right)\,
  \left[\frac{D_{\rm M}}{D_{\rm H}}\,
  \sqrt{1+\Omega_k\,\frac{D_{\rm M}^2}{D_{\rm H}^2}}
  -\frac{1}{\sqrt{|\Omega_k|}}\,
  {\rm arcsin}\left(\sqrt{|\Omega_k|}\,\frac{D_{\rm M}}{D_{\rm H}}\right)\right]
  & {\rm for}~\Omega_k<0
\end{array}
\right.
\end{equation}



\section{COMPAS configuration fiducial values}\label{sec:appendix_COMPAS_fiducial}

\begin{table*}[ht!]
\centering
\caption{Initial values and default settings for the \COMPAS fiducial model.}
%
\label{tab:app_COMPAS_fiducial}
% ?\textwidth}{l @{\extracolsep{\fill}}
\resizebox{\textwidth}{!}{%
% \begin{adjustbox}{max width=1\textwidth}
% \centering
\begin{tabular}{lll}
\hline  \hline
Description and name                                 														& Value/range                       & Note / setting   \\ \hline  \hline
\multicolumn{3}{c}{Initial conditions}                                                                      \\ \hline
Initial primary mass \monei                               															& $[5, 150]$\Msun    & \citet{Kroupa_2001} IMF  $\propto  {\monei}^{-\alpha}$  with $\alpha_{\rm{IMF}} = 2.3$ for stars above $5$\Msun	  \\
%
Initial mass ratio $\qi = \mtwoi / \monei $           												& $[0, 1]$                          &       We assume a flat mass ratio distribution  $p(\qi) \propto  1$ with \mtwoi $\geq 0.1\Msun$   \\
%
Initial semi-major axis \ai                                            											& $[0.01, 1000]$\AU & Distributed flat-in-log $p(\ai) \propto 1 / {\ai}$ \\
%
Initial metallicity \Zi                                           											& $[0.0001, 0.03]$                 & Distributed uniform-in-log   \\
%
Initial orbital eccentricity \ei                                 							 				& 0                                & All binaries are assumed to be circular at birth  \\
%
% initial rotation of stars                            															& 0                                 &                  \\  \hline
\hline
%initial mass function (IMF) slope 	$\alpha_{\rm{IMF}}$									&  $ 2.3$		& 	 for stars above $5$\Msun from \citet{2001MNRAS.322..231K} IMF\\  \hline
\multicolumn{3}{c}{Fiducial parameter settings:}                                                            \\ \hline
%
Stellar winds  for hydrogen rich stars                                   																&      \citet{Belczynski_2010a}    &   Based on {\citet{Vink_2000, Vink_2001}}, including  LBV wind mass loss with $f_{\rm{LBV}} = 1.5$   \\
%
Stellar winds for hydrogen-poor helium stars &  \citet{Belczynski_2010a} & Based on   {\citet{Hamann_1998}} and  {\citealt{Vink_2005}}  \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%% MASS TRANSFER THINGS %%%%%%%%%%%%%%%%%%%%%%%
%
Max transfer stability criteria & $\zeta$-prescription & Based on \citet[][]{Vigna-Gomez_2018} and references therein     \\
%
Mass transfer accretion rate & thermal timescale & Limited by thermal timescale for stars  \citet[][]{Hurley_2002, Vinciguerra_2020} \\
 & Eddington-limited  & Accretion rate is Eddington-limit for compact objects  \\
%
Non-conservative mass loss & isotropic re-emission &  {\citet[][]{Massevitch_1975, Bhattacharya_1991, Soberman_1997}} \\
& &  {\citet{Tauris_2006}} \\
%
Case BB mass transfer stability                                														& always stable         &       Based on  \citet{Tauris_2015, Tauris_2017, Vigna-Gomez_2018}         \\
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%% CE THINGS %%%%%%%%%%%%%%%%%%%%%%%
%
CE prescription & $\alpha-\lambda$ & Based on  \citet{Webbink_1984, deKool_1990}  \\
%
CE efficiency $\alpha$-parameter                     												& 1.0                               &              \\
%
CE $\lambda$-parameter                               													& $\lambda_{\rm{Nanjing}}$                             &        Based on \citet{Xu_2010a, Xu_2010b} and  \citet{Dominik_2012}       \\
%
Hertzsprung gap (HG) donor in {CE}                       														& pessimistic                       &  Defined in \citet{Dominik_2012}:  HG donors don't survive a {CE}  phase        \\
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%.    SN THINGS   %%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
{SN} natal kick magnitude \vk                          									& $[0, \infty)$\kms & Drawn from Maxwellian distribution with standard deviation $\sigma_{\rm{rms}}^{\rm{1D}}$          \\
%
 {SN} natal kick polar angle $\thetak$          											& $[0, \pi]$                        & $p(\thetak) = \sin(\thetak)/2$ \\
%
 {SN} natal kick azimuthal angle $\phi_k$                           					  	& $[0, 2\pi]$                        & Uniform $p(\phi) = 1/ (2 \pi)$   \\
%
 {SN} mean anomaly of the orbit                    											&     $[0, 2\pi]$                             & Uniformly distributed  \\
 %
Core-collapse  {SN} remnant mass prescription          									     &  delayed                     &  From \citet{Fryer_2012}, which  has no lower {BH} mass gap  \\%
%
USSN  remnant mass prescription          									     &  delayed                     &  From \citet{Fryer_2012}   \\%
%
ECSN  remnant mass presciption                        												&                                 $m_{\rm{f}} = 1.26\Msun$ &      Based on Equation~8 in \citet{Timmes_1996}          \\
%
Core-collapse  {SN}  velocity dispersion $\sigma_{\rm{rms}}^{\rm{1D}}$ 			& 265\kms           & 1D rms value based on              \citet{Hobbs_2005}                          \\
%
 USSN  and ECSN  velocity dispersion $\sigma_{\rm{rms}}^{\rm{1D}}$ 							 	& 30\kms             &            1D rms value based on e.g.,    \citet{Pfahl_2002, Podsiadlowski_2004}    \\
%
PISN / PPISN remnant mass prescription               											& \citet{Marchant_2019}                    &       As implemented in \citet{Stevenson_2019}      \\
Maximum NS mass                                      & $\rm{max}_{\rm{NS}} = 2.5$\Msun & Following \citet{Fryer_2012}            \\
Tides and rotation & & We do not include tides and/or rotation in this study\\
Binary fraction                                      & $f_{\rm{bin}} = 0.7$ &  \\
Solar metallicity \Zsun                             & $\rm{Z}_{\odot}\xspace = 0.0142$ & based on {\citet{Asplund_2009}} \\
%
%
\hline
\multicolumn{3}{c}{Simulation settings}                                                                     \\ \hline
Binary population synthesis code                                      & COMPAS &       \citet{Stevenson_2017, Barrett_2018, Vigna-Gomez_2018, Neijssel_2019} \\
& & \citet{Broekgaarden_2019, COMPAS_2022}.        \\
\hline \hline
\end{tabular}%
% \end{adjustbox}
}
\end{table*}



\end{document}
